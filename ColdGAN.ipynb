{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, OneHotEncoder\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# =============================================================================\n",
        "# 1. VERİ YÜKLEME VE TEMİZLEME (DÜZELTİLMİŞ KISIM)\n",
        "# =============================================================================\n",
        "def load_and_process_data():\n",
        "    print(\"Veriler Yükleniyor ve İşleniyor...\")\n",
        "\n",
        "    # --- DÜZELTME BURADA YAPILDI ---\n",
        "    # encoding='latin-1' eklendi. Eğer yine hata verirse 'cp1252' deneyebilirsin.\n",
        "    try:\n",
        "        places_df = pd.read_csv('paris_1000_mixed_places.csv', sep=';', encoding='latin-1')\n",
        "        users_df = pd.read_csv('users.csv', sep=';', encoding='latin-1')\n",
        "    except UnicodeDecodeError:\n",
        "        # latin-1 de çalışmazsa cp1252 dene\n",
        "        print(\"Latin-1 başarısız, cp1252 deneniyor...\")\n",
        "        places_df = pd.read_csv('paris_1000_mixed_places.csv', sep=';', encoding='cp1252')\n",
        "        users_df = pd.read_csv('users.csv', sep=';', encoding='cp1252')\n",
        "\n",
        "    # --- A. Mekan Verisi İşleme ---\n",
        "    # Kategorileri temizle ve listeye çevir\n",
        "    # NaN değerleri boş string yapıp string'e çeviriyoruz\n",
        "    places_df['category'] = places_df['category'].fillna('').astype(str)\n",
        "\n",
        "    # Virgülle ayrılmış kategorileri listeye çeviriyoruz\n",
        "    places_df['category_list'] = places_df['category'].apply(lambda x: [i.strip().lower() for i in x.split(',') if i.strip()])\n",
        "\n",
        "    # Mekanlar için özellik vektörü\n",
        "    mlb_places = MultiLabelBinarizer()\n",
        "    place_features = mlb_places.fit_transform(places_df['category_list'])\n",
        "\n",
        "    # GNN Embeddinglerini Simüle Etme (Hedef Vektör Boyutu: 64)\n",
        "    dummy_projection = np.random.rand(place_features.shape[1], 64)\n",
        "    place_embeddings = np.dot(place_features, dummy_projection)\n",
        "    place_embeddings = torch.tensor(place_embeddings, dtype=torch.float32)\n",
        "\n",
        "    # --- B. Kullanıcı Verisi İşleme (GİRDİ) ---\n",
        "    # İlgi alanlarını listeye çevir\n",
        "    users_df['interests'] = users_df['interests'].fillna('').astype(str)\n",
        "    users_df['interests_list'] = users_df['interests'].apply(lambda x: [i.strip().lower() for i in x.split(',') if i.strip()])\n",
        "\n",
        "    # 1. İlgi Alanlarını Vektöre Çevir\n",
        "    mlb_users = MultiLabelBinarizer()\n",
        "    user_interest_features = mlb_users.fit_transform(users_df['interests_list'])\n",
        "\n",
        "    # 2. Bütçe ve Yaş Grubunu Vektöre Çevir\n",
        "    # Eğer budget veya age_group boşsa hata vermesin diye fillna yapıyoruz\n",
        "    users_df['budget'] = users_df['budget'].fillna('Standard')\n",
        "    users_df['age_group'] = users_df['age_group'].fillna('25-34')\n",
        "\n",
        "    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "    user_demographics = ohe.fit_transform(users_df[['budget', 'age_group']])\n",
        "\n",
        "    # Tüm özellikleri birleştir\n",
        "    user_features = np.hstack([user_interest_features, user_demographics])\n",
        "    user_tensor = torch.tensor(user_features, dtype=torch.float32)\n",
        "\n",
        "    # --- C. Hedef Oluşturma (Eğitim İçin) ---\n",
        "    target_embeddings = []\n",
        "\n",
        "    # MLB class isimlerini alalım (index eşleşmesi için)\n",
        "    place_cats_list = list(mlb_places.classes_)\n",
        "\n",
        "    for keywords in users_df['interests_list']:\n",
        "        matched_indices = []\n",
        "\n",
        "        # Hızlandırma için basit mantık:\n",
        "        # Kullanıcının ilgi alanı kelimelerinden herhangi biri mekan kategorisinde geçiyor mu?\n",
        "        for idx, cats in enumerate(places_df['category_list']):\n",
        "            # Kesişim kümesi boş değilse eşleşme vardır\n",
        "            if set(keywords) & set(cats):\n",
        "                matched_indices.append(idx)\n",
        "\n",
        "        if matched_indices:\n",
        "            avg_emb = place_embeddings[matched_indices].mean(dim=0)\n",
        "        else:\n",
        "            avg_emb = torch.randn(64)\n",
        "        target_embeddings.append(avg_emb)\n",
        "\n",
        "    target_tensor = torch.stack(target_embeddings)\n",
        "\n",
        "    return {\n",
        "        'user_tensor': user_tensor,\n",
        "        'target_tensor': target_tensor,\n",
        "        'place_embeddings': place_embeddings,\n",
        "        'places_df': places_df,\n",
        "        'mlb_users': mlb_users,\n",
        "        'ohe': ohe,\n",
        "        'input_dim': user_tensor.shape[1],\n",
        "        'embedding_dim': 64\n",
        "    }\n",
        "\n",
        "# =============================================================================\n",
        "# 2. GAN MODELLERİ\n",
        "# =============================================================================\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# =============================================================================\n",
        "# 3. EĞİTİM FONKSİYONU\n",
        "# =============================================================================\n",
        "def train_coldgan(data_dict, epochs=300):\n",
        "    user_input = data_dict['user_tensor']\n",
        "    real_embeddings = data_dict['target_tensor']\n",
        "\n",
        "    generator = Generator(data_dict['input_dim'], data_dict['embedding_dim'])\n",
        "    discriminator = Discriminator(data_dict['embedding_dim'])\n",
        "\n",
        "    opt_g = optim.Adam(generator.parameters(), lr=0.001)\n",
        "    opt_d = optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    print(f\"\\nModel Eğitiliyor ({epochs} Epoch)...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # --- Train Discriminator ---\n",
        "        opt_d.zero_grad()\n",
        "        real_preds = discriminator(real_embeddings)\n",
        "        d_loss_real = criterion(real_preds, torch.ones_like(real_preds))\n",
        "\n",
        "        fake_embeddings = generator(user_input)\n",
        "        fake_preds = discriminator(fake_embeddings.detach())\n",
        "        d_loss_fake = criterion(fake_preds, torch.zeros_like(fake_preds))\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "        d_loss.backward()\n",
        "        opt_d.step()\n",
        "\n",
        "        # --- Train Generator ---\n",
        "        opt_g.zero_grad()\n",
        "        fake_embeddings_2 = generator(user_input)\n",
        "        preds_2 = discriminator(fake_embeddings_2)\n",
        "\n",
        "        g_loss_adv = criterion(preds_2, torch.ones_like(preds_2))\n",
        "        g_loss_content = nn.MSELoss()(fake_embeddings_2, real_embeddings)\n",
        "\n",
        "        g_loss = g_loss_adv + (10 * g_loss_content)\n",
        "        g_loss.backward()\n",
        "        opt_g.step()\n",
        "\n",
        "        if epoch % 50 == 0:\n",
        "            print(f\"Epoch {epoch} | D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    print(\"Eğitim Tamamlandı!\")\n",
        "    return generator\n",
        "\n",
        "# =============================================================================\n",
        "# 4. YENİ KULLANICI TEST FONKSİYONU\n",
        "# =============================================================================\n",
        "def test_new_user(generator, data_dict, interests_str, budget_str, age_str):\n",
        "    print(f\"\\n--- Yeni Kullanıcı Testi: {interests_str} | {budget_str} ---\")\n",
        "\n",
        "    interests_list = [i.strip().lower() for i in interests_str.split(',')]\n",
        "    try:\n",
        "        input_interests = data_dict['mlb_users'].transform([interests_list])\n",
        "    except ValueError:\n",
        "        valid_interests = [i for i in interests_list if i in data_dict['mlb_users'].classes_]\n",
        "        input_interests = data_dict['mlb_users'].transform([valid_interests])\n",
        "\n",
        "    input_demo = pd.DataFrame({'budget': [budget_str], 'age_group': [age_str]})\n",
        "    input_demo_vec = data_dict['ohe'].transform(input_demo)\n",
        "\n",
        "    input_vector = np.hstack([input_interests, input_demo_vec])\n",
        "    input_tensor = torch.tensor(input_vector, dtype=torch.float32)\n",
        "\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        generated_embedding = generator(input_tensor)\n",
        "\n",
        "    place_embs_np = data_dict['place_embeddings'].numpy()\n",
        "    gen_emb_np = generated_embedding.numpy()\n",
        "\n",
        "    scores = cosine_similarity(gen_emb_np, place_embs_np)[0]\n",
        "\n",
        "    top_indices = scores.argsort()[-5:][::-1]\n",
        "\n",
        "    print(\"\\nÖnerilen Mekanlar:\")\n",
        "    for idx in top_indices:\n",
        "        place = data_dict['places_df'].iloc[idx]\n",
        "        score = scores[idx]\n",
        "        print(f\"- {place['name']} ({place['category']}) | Skor: {score:.3f}\")\n",
        "\n",
        "# =============================================================================\n",
        "# ÇALIŞTIRMA KISMI\n",
        "# =============================================================================\n",
        "\n",
        "# 1. Veriyi Hazırla\n",
        "data = load_and_process_data()\n",
        "\n",
        "# 2. Modeli Eğit\n",
        "trained_gen = train_coldgan(data, epochs=200)\n",
        "\n",
        "# 3. MANUEL TEST - KENDİ DENEMELERİNİ BURADAN YAPABİLİRSİN\n",
        "# Örnek 1: Alışveriş seven (CSV'de 'shopping' var), Lüks bütçeli\n",
        "test_new_user(\n",
        "    trained_gen,\n",
        "    data,\n",
        "    interests_str=\"shopping\",\n",
        "    budget_str=\"Luxury\",\n",
        "    age_str=\"25-34\"\n",
        ")\n",
        "\n",
        "# Örnek 2: Park ve doğa seven\n",
        "test_new_user(\n",
        "    trained_gen,\n",
        "    data,\n",
        "    interests_str=\"parks, nature\",\n",
        "    budget_str=\"Standard\",\n",
        "    age_str=\"55\"\n",
        ")"
      ],
      "metadata": {
        "id": "93Bhw_Z6eIYS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}