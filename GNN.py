import pandas as pd
import torch
import torch.nn.functional as F
import random
import numpy as np
from torch_geometric.data import HeteroData
from torch_geometric.nn import SAGEConv, to_hetero

# ---------------------------------------------------------
# 1. VERÄ° YÃœKLEME VE Ã–N Ä°ÅLEME
# ---------------------------------------------------------
def load_real_data():
    print("Veriler yÃ¼kleniyor...")
    
    # 1. Places DosyasÄ±nÄ± Oku (Encoding hatasÄ± dÃ¼zeltildi)
    # 'latin-1' veya 'cp1252' genellikle TÃ¼rkÃ§e/FransÄ±zca karakter iÃ§eren Windows dosyalarÄ±nÄ± Ã§Ã¶zer.
    places_df = pd.read_csv('paris_1000_mixed_places.csv', sep=';', encoding='latin-1')
    
    # 2. Users DosyasÄ±nÄ± Oku
    # DÄ°KKAT: Benim verdiÄŸim users listesini kopyaladÄ±ysanÄ±z ayraÃ§ virgÃ¼ldÃ¼r (sep=',').
    # Excel'den "CSV (NoktalÄ± virgÃ¼l ile ayrÄ±lmÄ±ÅŸ)" olarak kaydettiyseniz sep=';' yapÄ±n.
    # AÅŸaÄŸÄ±daki kod her iki durumu da dener:
    try:
        # Ã–nce virgÃ¼l ile dene (Benim verdiÄŸim format)
        users_df = pd.read_csv('users.csv', sep=',')
        # EÄŸer tek sÃ¼tun okursa (yani ayraÃ§ yanlÄ±ÅŸsa), noktalÄ± virgÃ¼l dene
        if users_df.shape[1] < 2:
            users_df = pd.read_csv('users.csv', sep=';', encoding='latin-1')
    except:
        # Hata verirse direkt noktalÄ± virgÃ¼l dene
        users_df = pd.read_csv('users.csv', sep=';', encoding='latin-1')

    # ID Mapping
    place_id_map = {id: i for i, id in enumerate(places_df['name'].unique())} 
    
    num_places = len(places_df)
    num_users = len(users_df)

    print(f"Toplam MekÃ¢n: {num_places}, Toplam KullanÄ±cÄ±: {num_users}")

    # 3. Kategori Ä°ÅŸleme (Place Features)
    # BoÅŸ veya hatalÄ± kategorileri 'General' olarak doldur
    places_df['category'] = places_df['category'].fillna('General')
    
    # Kategorinin ilk kelimesini al
    places_df['simple_cat'] = places_df['category'].astype(str).apply(lambda x: x.split(',')[0].strip())
    unique_cats = places_df['simple_cat'].unique()
    cat_to_idx = {cat: i for i, cat in enumerate(unique_cats)}
    
    # Place Features (One-Hot Encoding)
    place_features = torch.zeros(num_places, len(unique_cats))
    for idx, row in places_df.iterrows():
        cat_idx = cat_to_idx.get(row['simple_cat'], 0)
        place_features[idx][cat_idx] = 1.0

    # 4. KullanÄ±cÄ± Ä°ÅŸleme (User Features)
    unique_personas = users_df['persona'].unique()
    persona_to_idx = {p: i for i, p in enumerate(unique_personas)}
    
    user_features = torch.zeros(num_users, len(unique_personas))
    for idx, row in users_df.iterrows():
        p_idx = persona_to_idx.get(row['persona'], 0)
        user_features[idx][p_idx] = 1.0

    # 5. Sentetik EtkileÅŸim (Edge) Ãœretimi
    src_list = []
    dst_list = []
    
    interest_map = {
        "Culture & Arts Lover": ["Museums", "Landmarks", "Arts", "History"],
        "Gastronome": ["Restaurants", "French", "Cafes", "Wine"],
        "Night Owl": ["Bars", "Cocktail", "Nightlife", "Clubs"],
        "Nature Lover": ["Parks", "Gardens"],
        "Shopaholic": ["Shopping", "Fashion"],
        "Tourist": ["Hotels", "Landmarks", "Museums"]
    }

    print("Sentetik etkileÅŸimler Ã¼retiliyor...")
    for u_idx, user in users_df.iterrows():
        user_persona = user['persona']
        liked_categories = interest_map.get(user_persona, [])
        
        # Rastgele 20 mekan seÃ§ip kontrol et
        # (Mekan sayÄ±sÄ± az ise hata vermemesi iÃ§in min alÄ±yoruz)
        sample_size = min(20, num_places)
        sample_indices = random.sample(range(num_places), sample_size)
        
        for p_idx in sample_indices:
            place_cat = places_df.iloc[p_idx]['simple_cat']
            
            # Kategori eÅŸleÅŸmesi veya ÅŸans faktÃ¶rÃ¼
            if any(interest in place_cat for interest in liked_categories) or random.random() < 0.1:
                src_list.append(u_idx)
                dst_list.append(p_idx)

    edge_index = torch.tensor([src_list, dst_list], dtype=torch.long)
    print(f"Toplam Ãœretilen BaÄŸlantÄ± (EtkileÅŸim): {edge_index.shape[1]}")

    data = HeteroData()
    data['user'].x = user_features
    data['place'].x = place_features
    data['user', 'rates', 'place'].edge_index = edge_index
    data['place', 'rated_by', 'user'].edge_index = edge_index.flip(0)
    
    return data, places_df, users_df

# ---------------------------------------------------------
# 2. MODEL MÄ°MARÄ°SÄ° (SAGEConv)
# ---------------------------------------------------------
class GNN(torch.nn.Module):
    def __init__(self, hidden_channels, out_channels):
        super().__init__()
        self.conv1 = SAGEConv((-1, -1), hidden_channels)
        self.conv2 = SAGEConv((-1, -1), out_channels)

    def forward(self, x, edge_index):
        x = self.conv1(x, edge_index)
        x = x.relu()
        x = self.conv2(x, edge_index)
        return x

class HeteroGNN(torch.nn.Module):
    def __init__(self, metadata, hidden_channels, out_channels):
        super().__init__()
        self.gnn = GNN(hidden_channels, out_channels)
        self.gnn = to_hetero(self.gnn, metadata, aggr='sum')

    def forward(self, x_dict, edge_index_dict):
        return self.gnn(x_dict, edge_index_dict)

# ---------------------------------------------------------
# 3. EÄÄ°TÄ°M DÃ–NGÃœSÃœ (NEGATIVE SAMPLING EKLENMÄ°Å)
# ---------------------------------------------------------
def train_model():
    # Veriyi YÃ¼kle
    data, places_df, users_df = load_real_data()
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    data = data.to(device)

    # Model Parametreleri
    # Hidden channels'Ä± feature boyutuna gÃ¶re ayarlamak iyi olur ama sabit de Ã§alÄ±ÅŸÄ±r.
    model = HeteroGNN(data.metadata(), hidden_channels=32, out_channels=16).to(device)
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

    print("\nModel EÄŸitimi BaÅŸlÄ±yor...")
    
    for epoch in range(101):
        model.train()
        optimizer.zero_grad()
        
        # 1. Forward Pass
        node_embeddings = model(data.x_dict, data.edge_index_dict)
        
        # 2. Positive Sampling (GerÃ§ek BaÄŸlantÄ±lar)
        pos_edge_index = data['user', 'rates', 'place'].edge_index
        pos_user_emb = node_embeddings['user'][pos_edge_index[0]]
        pos_place_emb = node_embeddings['place'][pos_edge_index[1]]
        # Skor: Dot Product
        pos_scores = (pos_user_emb * pos_place_emb).sum(dim=1)
        
        # 3. Negative Sampling (Olmayan BaÄŸlantÄ±lar - Rastgele)
        # Modelin "her ÅŸeye evet" demesini engellemek iÃ§in
        neg_u = torch.randint(0, data['user'].num_nodes, (pos_edge_index.size(1),), device=device)
        neg_p = torch.randint(0, data['place'].num_nodes, (pos_edge_index.size(1),), device=device)
        
        neg_user_emb = node_embeddings['user'][neg_u]
        neg_place_emb = node_embeddings['place'][neg_p]
        neg_scores = (neg_user_emb * neg_place_emb).sum(dim=1)
        
        # 4. Loss (BCEWithLogitsLoss)
        # Pozitifler 1 olsun, Negatifler 0 olsun
        pos_loss = F.binary_cross_entropy_with_logits(pos_scores, torch.ones_like(pos_scores))
        neg_loss = F.binary_cross_entropy_with_logits(neg_scores, torch.zeros_like(neg_scores))
        loss = pos_loss + neg_loss
        
        loss.backward()
        optimizer.step()
        
        if epoch % 10 == 0:
            print(f"Epoch: {epoch:03d}, Loss: {loss.item():.4f}")

    return model, data, places_df, users_df

# ---------------------------------------------------------
# 4. TEST VE Ã–NERÄ°
# ---------------------------------------------------------
if __name__ == "__main__":
    model, data, places_df, users_df = train_model()
    
    print("\n--- Ã–NERÄ° TESTÄ° ---")
    model.eval()
    with torch.no_grad():
        embeddings = model(data.x_dict, data.edge_index_dict)
        
        # Test iÃ§in bir kullanÄ±cÄ± seÃ§elim (Ã–rn: Index 3 -> Mehmet Williams / Culture Lover)
        test_user_idx = 3 
        user_info = users_df.iloc[test_user_idx]
        print(f"\nKullanÄ±cÄ±: {user_info['name']}")
        print(f"Persona: {user_info['persona']}")
        print(f"Ä°lgi AlanlarÄ±: {user_info['interests']}")
        
        # TÃ¼m mekanlar iÃ§in skor hesapla
        user_vec = embeddings['user'][test_user_idx]
        place_vecs = embeddings['place']
        
        # Matrix Multiplication ile skorlar
        scores = (place_vecs @ user_vec).sigmoid()
        
        # En yÃ¼ksek 5 Ã¶neri
        top_k = 5
        top_scores, top_indices = torch.topk(scores, top_k)
        
        print(f"\nModelin Ã–nerdiÄŸi Top {top_k} MekÃ¢n:")
        for score, idx in zip(top_scores, top_indices):
            idx = idx.item()
            place_name = places_df.iloc[idx]['name']
            place_cat = places_df.iloc[idx]['category']
            print(f"- {place_name} ({place_cat}) [Skor: {score:.4f}]")
# ... (YukarÄ±daki kodlar aynÄ± kalacak) ...

def get_recommendations_for_user(user_name_or_id, model, data, places_df, users_df, top_k=5):
    """
    Ä°smi veya ID'si verilen kullanÄ±cÄ± iÃ§in GNN modelini kullanarak Ã¶neri yapar.
    """
    model.eval()
    
    # 1. KullanÄ±cÄ±yÄ± Bul (Index Mapping)
    # KullanÄ±cÄ± adÄ±nda arama yap
    if isinstance(user_name_or_id, str):
        target_user = users_df[users_df['name'].str.contains(user_name_or_id, case=False, na=False)]
    else:
        # ID ise (Ã¶rn: 1003)
        target_user = users_df[users_df['user_id'] == user_name_or_id]
        
    if target_user.empty:
        print(f"âŒ KullanÄ±cÄ± bulunamadÄ±: {user_name_or_id}")
        return

    # KullanÄ±cÄ±nÄ±n DataFrame'deki indeksini (0, 1, 2...) al
    # GNN tensÃ¶rleri bu indekse gÃ¶re Ã§alÄ±ÅŸÄ±r.
    user_idx = target_user.index[0]
    real_user_id = target_user.iloc[0]['user_id']
    user_name = target_user.iloc[0]['name']
    user_persona = target_user.iloc[0]['persona']
    
    print(f"\nğŸ” ANALÄ°Z EDÄ°LEN KULLANICI:")
    print(f"   ID: {real_user_id} | Ä°sim: {user_name}")
    print(f"   Persona: {user_persona} (Ä°lgi AlanlarÄ±: {target_user.iloc[0]['interests']})")

    # 2. Embeddingleri Ã‡ek ve Hesapla
    with torch.no_grad():
        embeddings = model(data.x_dict, data.edge_index_dict)
        
        user_vec = embeddings['user'][user_idx]  # SeÃ§ilen kullanÄ±cÄ±nÄ±n vektÃ¶rÃ¼
        place_vecs = embeddings['place']         # TÃ¼m mekanlarÄ±n vektÃ¶rleri
        
        # Skorlama: Dot Product + Sigmoid (0 ile 1 arasÄ± olasÄ±lÄ±k)
        scores = (place_vecs @ user_vec).sigmoid()
        
        # En yÃ¼ksek skorlu Top K mekanÄ± bul
        top_scores, top_indices = torch.topk(scores, top_k)
        
    # 3. SonuÃ§larÄ± YazdÄ±r
    print(f"\nğŸ¯ MODELÄ°N Ã–NERÄ°LERÄ° ({user_persona} iÃ§in):")
    print("-" * 60)
    print(f"{'MEKAN ADI':<30} | {'KATEGORÄ°':<20} | {'SKOR'}")
    print("-" * 60)
    
    for score, idx in zip(top_scores, top_indices):
        idx = idx.item()
        place_name = places_df.iloc[idx]['name']
        place_cat = places_df.iloc[idx]['category']
        # Kategori ismini kÄ±saltalÄ±m
        place_cat_short = place_cat.split(',')[0][:20]
        
        print(f"{place_name:<30} | {place_cat_short:<20} | {score:.4f}")
    print("-" * 60)

# --- ANA Ã‡ALIÅTIRMA BLOÄU ---
if __name__ == "__main__":
    # 1. Modeli EÄŸit
    model, data, places_df, users_df = train_model()
    
    # 2. Test Etmek Ä°stediÄŸiniz KullanÄ±cÄ±larÄ± Buraya YazÄ±n
    # FarklÄ± personalarÄ± deneyerek modelin tutarlÄ±lÄ±ÄŸÄ±nÄ± Ã¶lÃ§Ã¼n.
    
    print("\n" + "="*40)
    print("      TEST SENARYOLARI BAÅLIYOR      ")
    print("="*40)

    # SENARYO 1: KÃ¼ltÃ¼r Sever (Culture & Arts Lover)
    # Beklenti: MÃ¼zeler ve Tarihi yerler Ã¶nermesi
    get_recommendations_for_user("Mehmet Williams", model, data, places_df, users_df)

    # SENARYO 2: Gurme (Gastronome)
    # Beklenti: Restoran ve Kafeler Ã¶nermesi
    get_recommendations_for_user("Pierre Arslan", model, data, places_df, users_df)

    # SENARYO 3: DoÄŸa Sever (Nature Lover)
    # Beklenti: Park ve BahÃ§eler Ã¶nermesi
    get_recommendations_for_user("Zeynep Davis", model, data, places_df, users_df)
    
    while True:
        isim = input("\nMerak ettiÄŸiniz kullanÄ±cÄ± adÄ± (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q'): ")
        if isim == 'q': break
        get_recommendations_for_user(isim, model, data, places_df, users_df)
