{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import numpy as np\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.nn import SAGEConv, to_hetero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_real_data():\n",
    "    print(\"Veriler yÃ¼kleniyor...\")\n",
    "    \n",
    "    # 1. Places DosyasÄ±nÄ± Oku (Encoding hatasÄ± dÃ¼zeltildi)\n",
    "    # 'latin-1' veya 'cp1252' genellikle TÃ¼rkÃ§e/FransÄ±zca karakter iÃ§eren Windows dosyalarÄ±nÄ± Ã§Ã¶zer.\n",
    "    places_df = pd.read_csv('paris_1000_mixed_places.csv', sep=';', encoding='latin-1')\n",
    "    \n",
    "    # 2. Users DosyasÄ±nÄ± Oku\n",
    "    # DÄ°KKAT: Benim verdiÄŸim users listesini kopyaladÄ±ysanÄ±z ayraÃ§ virgÃ¼ldÃ¼r (sep=',').\n",
    "    # Excel'den \"CSV (NoktalÄ± virgÃ¼l ile ayrÄ±lmÄ±ÅŸ)\" olarak kaydettiyseniz sep=';' yapÄ±n.\n",
    "    # AÅŸaÄŸÄ±daki kod her iki durumu da dener:\n",
    "    try:\n",
    "        # Ã–nce virgÃ¼l ile dene (Benim verdiÄŸim format)\n",
    "        users_df = pd.read_csv('users.csv', sep=',')\n",
    "        # EÄŸer tek sÃ¼tun okursa (yani ayraÃ§ yanlÄ±ÅŸsa), noktalÄ± virgÃ¼l dene\n",
    "        if users_df.shape[1] < 2:\n",
    "            users_df = pd.read_csv('users.csv', sep=';', encoding='latin-1')\n",
    "    except:\n",
    "        # Hata verirse direkt noktalÄ± virgÃ¼l dene\n",
    "        users_df = pd.read_csv('users.csv', sep=';', encoding='latin-1')\n",
    "\n",
    "    # ID Mapping\n",
    "    place_id_map = {id: i for i, id in enumerate(places_df['name'].unique())} \n",
    "    \n",
    "    num_places = len(places_df)\n",
    "    num_users = len(users_df)\n",
    "    print(f\"Toplam MekÃ¢n: {num_places}, Toplam KullanÄ±cÄ±: {num_users}\")\n",
    "\n",
    "    # 3. Kategori Ä°ÅŸleme (Place Features)\n",
    "    # BoÅŸ veya hatalÄ± kategorileri 'General' olarak doldur\n",
    "    places_df['category'] = places_df['category'].fillna('General')\n",
    "    \n",
    "    # Kategorinin ilk kelimesini al\n",
    "    places_df['simple_cat'] = places_df['category'].astype(str).apply(lambda x: x.split(',')[0].strip())\n",
    "    unique_cats = places_df['simple_cat'].unique()\n",
    "    cat_to_idx = {cat: i for i, cat in enumerate(unique_cats)}\n",
    "    \n",
    "    # Place Features (One-Hot Encoding)\n",
    "    place_features = torch.zeros(num_places, len(unique_cats))\n",
    "    for idx, row in places_df.iterrows():\n",
    "        cat_idx = cat_to_idx.get(row['simple_cat'], 0)\n",
    "        place_features[idx][cat_idx] = 1.0\n",
    "\n",
    "    # 4. KullanÄ±cÄ± Ä°ÅŸleme (User Features)\n",
    "    unique_personas = users_df['persona'].unique()\n",
    "    persona_to_idx = {p: i for i, p in enumerate(unique_personas)}\n",
    "    \n",
    "    user_features = torch.zeros(num_users, len(unique_personas))\n",
    "    for idx, row in users_df.iterrows():\n",
    "        p_idx = persona_to_idx.get(row['persona'], 0)\n",
    "        user_features[idx][p_idx] = 1.0\n",
    "\n",
    "    # 5. Sentetik EtkileÅŸim (Edge) Ãœretimi\n",
    "    src_list = []\n",
    "    dst_list = []\n",
    "    \n",
    "    interest_map = {\n",
    "        \"Culture & Arts Lover\": [\"Museums\", \"Landmarks\", \"Arts\", \"History\"],\n",
    "        \"Gastronome\": [\"Restaurants\", \"French\", \"Cafes\", \"Wine\"],\n",
    "        \"Night Owl\": [\"Bars\", \"Cocktail\", \"Nightlife\", \"Clubs\"],\n",
    "        \"Nature Lover\": [\"Parks\", \"Gardens\"],\n",
    "        \"Shopaholic\": [\"Shopping\", \"Fashion\"],\n",
    "        \"Tourist\": [\"Hotels\", \"Landmarks\", \"Museums\"]\n",
    "    }\n",
    "    print(\"Sentetik etkileÅŸimler Ã¼retiliyor...\")\n",
    "    for u_idx, user in users_df.iterrows():\n",
    "        user_persona = user['persona']\n",
    "        liked_categories = interest_map.get(user_persona, [])\n",
    "        \n",
    "        # Rastgele 20 mekan seÃ§ip kontrol et\n",
    "        # (Mekan sayÄ±sÄ± az ise hata vermemesi iÃ§in min alÄ±yoruz)\n",
    "        sample_size = min(20, num_places)\n",
    "        sample_indices = random.sample(range(num_places), sample_size)\n",
    "        \n",
    "        for p_idx in sample_indices:\n",
    "            place_cat = places_df.iloc[p_idx]['simple_cat']\n",
    "            \n",
    "            # Kategori eÅŸleÅŸmesi veya ÅŸans faktÃ¶rÃ¼\n",
    "            if any(interest in place_cat for interest in liked_categories) or random.random() < 0.1:\n",
    "                src_list.append(u_idx)\n",
    "                dst_list.append(p_idx)\n",
    "    edge_index = torch.tensor([src_list, dst_list], dtype=torch.long)\n",
    "    print(f\"Toplam Ãœretilen BaÄŸlantÄ± (EtkileÅŸim): {edge_index.shape[1]}\")\n",
    "    data = HeteroData()\n",
    "    data['user'].x = user_features\n",
    "    data['place'].x = place_features\n",
    "    data['user', 'rates', 'place'].edge_index = edge_index\n",
    "    data['place', 'rated_by', 'user'].edge_index = edge_index.flip(0)\n",
    "    \n",
    "    return data, places_df, users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
    "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, metadata, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.gnn = GNN(hidden_channels, out_channels)\n",
    "        self.gnn = to_hetero(self.gnn, metadata, aggr='sum')\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        return self.gnn(x_dict, edge_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    # Veriyi YÃ¼kle\n",
    "    data, places_df, users_df = load_real_data()\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    data = data.to(device)\n",
    "\n",
    "    # Model Parametreleri\n",
    "    # Hidden channels'Ä± feature boyutuna gÃ¶re ayarlamak iyi olur ama sabit de Ã§alÄ±ÅŸÄ±r.\n",
    "    model = HeteroGNN(data.metadata(), hidden_channels=32, out_channels=16).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    print(\"\\nModel EÄŸitimi BaÅŸlÄ±yor...\")\n",
    "    \n",
    "    for epoch in range(101):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 1. Forward Pass\n",
    "        node_embeddings = model(data.x_dict, data.edge_index_dict)\n",
    "        \n",
    "        # 2. Positive Sampling (GerÃ§ek BaÄŸlantÄ±lar)\n",
    "        pos_edge_index = data['user', 'rates', 'place'].edge_index\n",
    "        pos_user_emb = node_embeddings['user'][pos_edge_index[0]]\n",
    "        pos_place_emb = node_embeddings['place'][pos_edge_index[1]]\n",
    "        # Skor: Dot Product\n",
    "        pos_scores = (pos_user_emb * pos_place_emb).sum(dim=1)\n",
    "        \n",
    "        # 3. Negative Sampling (Olmayan BaÄŸlantÄ±lar - Rastgele)\n",
    "        # Modelin \"her ÅŸeye evet\" demesini engellemek iÃ§in\n",
    "        neg_u = torch.randint(0, data['user'].num_nodes, (pos_edge_index.size(1),), device=device)\n",
    "        neg_p = torch.randint(0, data['place'].num_nodes, (pos_edge_index.size(1),), device=device)\n",
    "        \n",
    "        neg_user_emb = node_embeddings['user'][neg_u]\n",
    "        neg_place_emb = node_embeddings['place'][neg_p]\n",
    "        neg_scores = (neg_user_emb * neg_place_emb).sum(dim=1)\n",
    "        \n",
    "        # 4. Loss (BCEWithLogitsLoss)\n",
    "        # Pozitifler 1 olsun, Negatifler 0 olsun\n",
    "        pos_loss = F.binary_cross_entropy_with_logits(pos_scores, torch.ones_like(pos_scores))\n",
    "        neg_loss = F.binary_cross_entropy_with_logits(neg_scores, torch.zeros_like(neg_scores))\n",
    "        loss = pos_loss + neg_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch: {epoch:03d}, Loss: {loss.item():.4f}\")\n",
    "    return model, data, places_df, users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model, data, places_df, users_df = train_model()\n",
    "    \n",
    "    print(\"\\n--- Ã–NERÄ° TESTÄ° ---\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data.x_dict, data.edge_index_dict)\n",
    "        \n",
    "        # Test iÃ§in bir kullanÄ±cÄ± seÃ§elim (Ã–rn: Index 3 -> Mehmet Williams / Culture Lover)\n",
    "        test_user_idx = 3 \n",
    "        user_info = users_df.iloc[test_user_idx]\n",
    "        print(f\"\\nKullanÄ±cÄ±: {user_info['name']}\")\n",
    "        print(f\"Persona: {user_info['persona']}\")\n",
    "        print(f\"Ä°lgi AlanlarÄ±: {user_info['interests']}\")\n",
    "        \n",
    "        # TÃ¼m mekanlar iÃ§in skor hesapla\n",
    "        user_vec = embeddings['user'][test_user_idx]\n",
    "        place_vecs = embeddings['place']\n",
    "        \n",
    "        # Matrix Multiplication ile skorlar\n",
    "        scores = (place_vecs @ user_vec).sigmoid()\n",
    "        \n",
    "        # En yÃ¼ksek 5 Ã¶neri\n",
    "        top_k = 5\n",
    "        top_scores, top_indices = torch.topk(scores, top_k)\n",
    "        \n",
    "        print(f\"\\nModelin Ã–nerdiÄŸi Top {top_k} MekÃ¢n:\")\n",
    "        for score, idx in zip(top_scores, top_indices):\n",
    "            idx = idx.item()\n",
    "            place_name = places_df.iloc[idx]['name']\n",
    "            place_cat = places_df.iloc[idx]['category']\n",
    "            print(f\"- {place_name} ({place_cat}) [Skor: {score:.4f}]\")\n",
    "# ... (YukarÄ±daki kodlar aynÄ± kalacak) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_for_user(user_name_or_id, model, data, places_df, users_df, top_k=5):\n",
    "    \"\"\"\n",
    "    Ä°smi veya ID'si verilen kullanÄ±cÄ± iÃ§in GNN modelini kullanarak Ã¶neri yapar.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. KullanÄ±cÄ±yÄ± Bul (Index Mapping)\n",
    "    # KullanÄ±cÄ± adÄ±nda arama yap\n",
    "    if isinstance(user_name_or_id, str):\n",
    "        target_user = users_df[users_df['name'].str.contains(user_name_or_id, case=False, na=False)]\n",
    "    else:\n",
    "        # ID ise (Ã¶rn: 1003)\n",
    "        target_user = users_df[users_df['user_id'] == user_name_or_id]\n",
    "        \n",
    "    if target_user.empty:\n",
    "        print(f\"âŒ KullanÄ±cÄ± bulunamadÄ±: {user_name_or_id}\")\n",
    "        return\n",
    "\n",
    "    # KullanÄ±cÄ±nÄ±n DataFrame'deki indeksini (0, 1, 2...) al\n",
    "    # GNN tensÃ¶rleri bu indekse gÃ¶re Ã§alÄ±ÅŸÄ±r.\n",
    "    user_idx = target_user.index[0]\n",
    "    real_user_id = target_user.iloc[0]['user_id']\n",
    "    user_name = target_user.iloc[0]['name']\n",
    "    user_persona = target_user.iloc[0]['persona']\n",
    "    \n",
    "    print(f\"\\nğŸ” ANALÄ°Z EDÄ°LEN KULLANICI:\")\n",
    "    print(f\"   ID: {real_user_id} | Ä°sim: {user_name}\")\n",
    "    print(f\"   Persona: {user_persona} (Ä°lgi AlanlarÄ±: {target_user.iloc[0]['interests']})\")\n",
    "\n",
    "    # 2. Embeddingleri Ã‡ek ve Hesapla\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(data.x_dict, data.edge_index_dict)\n",
    "        \n",
    "        user_vec = embeddings['user'][user_idx]  # SeÃ§ilen kullanÄ±cÄ±nÄ±n vektÃ¶rÃ¼\n",
    "        place_vecs = embeddings['place']         # TÃ¼m mekanlarÄ±n vektÃ¶rleri\n",
    "        \n",
    "        # Skorlama: Dot Product + Sigmoid (0 ile 1 arasÄ± olasÄ±lÄ±k)\n",
    "        scores = (place_vecs @ user_vec).sigmoid()\n",
    "        \n",
    "        # En yÃ¼ksek skorlu Top K mekanÄ± bul\n",
    "        top_scores, top_indices = torch.topk(scores, top_k)\n",
    "        \n",
    "    # 3. SonuÃ§larÄ± YazdÄ±r\n",
    "    print(f\"\\nğŸ¯ MODELÄ°N Ã–NERÄ°LERÄ° ({user_persona} iÃ§in):\")\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'MEKAN ADI':<30} | {'KATEGORÄ°':<20} | {'SKOR'}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for score, idx in zip(top_scores, top_indices):\n",
    "        idx = idx.item()\n",
    "        place_name = places_df.iloc[idx]['name']\n",
    "        place_cat = places_df.iloc[idx]['category']\n",
    "        # Kategori ismini kÄ±saltalÄ±m\n",
    "        place_cat_short = place_cat.split(',')[0][:20]\n",
    "        \n",
    "        print(f\"{place_name:<30} | {place_cat_short:<20} | {score:.4f}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- ANA Ã‡ALIÅTIRMA BLOÄU ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # 1. Modeli EÄŸit\n",
    "    model, data, places_df, users_df = train_model()\n",
    "    \n",
    "    # 2. Test Etmek Ä°stediÄŸiniz KullanÄ±cÄ±larÄ± Buraya YazÄ±n\n",
    "    # FarklÄ± personalarÄ± deneyerek modelin tutarlÄ±lÄ±ÄŸÄ±nÄ± Ã¶lÃ§Ã¼n.\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"      TEST SENARYOLARI BAÅLIYOR      \")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # SENARYO 1: KÃ¼ltÃ¼r Sever (Culture & Arts Lover)\n",
    "    # Beklenti: MÃ¼zeler ve Tarihi yerler Ã¶nermesi\n",
    "    get_recommendations_for_user(\"Mehmet Williams\", model, data, places_df, users_df)\n",
    "\n",
    "    # SENARYO 2: Gurme (Gastronome)\n",
    "    # Beklenti: Restoran ve Kafeler Ã¶nermesi\n",
    "    get_recommendations_for_user(\"Pierre Arslan\", model, data, places_df, users_df)\n",
    "\n",
    "    # SENARYO 3: DoÄŸa Sever (Nature Lover)\n",
    "    # Beklenti: Park ve BahÃ§eler Ã¶nermesi\n",
    "    get_recommendations_for_user(\"Zeynep Davis\", model, data, places_df, users_df)\n",
    "    \n",
    "    while True:\n",
    "        isim = input(\"\\nMerak ettiÄŸiniz kullanÄ±cÄ± adÄ± (Ã‡Ä±kÄ±ÅŸ iÃ§in 'q'): \")\n",
    "        if isim == 'q': break\n",
    "        get_recommendations_for_user(isim, model, data, places_df, users_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
